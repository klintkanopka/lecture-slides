---
level: 1
layout: section
transition: fade
---

# Wrap Up

---
level: 2
---

# Recap

- Regularization puts a penalty on the likelihood proportional to the length of the parameter vector
    - This shrinks parameters toward zero
    - Ridge regression shrinks them slightly
    - LASSO regression tends to force parameters to be zero
- Resampling is a way to estimate things that are difficult to know analytically
    - The jackknife drops single observations to create new datasets of approximately the same size
    - The bootstrap resamples _with replacement_ to create new datasets the same size as your old data
- Regularization and the bootstrap are probably the two most generalizable applied techniques you'll learn here!



---
level: 3
---

# Final Thoughts

- [PollEv.com/klintkanopka](https://PollEv.com/klintkanopka)
